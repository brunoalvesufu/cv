{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Tech Problems.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brunoalvesufu/cv/blob/master/Tech_Problems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "VuLxMQWal2O2",
        "colab_type": "code",
        "outputId": "5c7a32f3-e2dd-420c-aa07-9c635525862a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Caminhonetes.zip\n",
            "/content/.config/.last_update_check.json\n",
            "/content/.config/active_config\n",
            "/content/.config/config_sentinel\n",
            "/content/.config/gce\n",
            "/content/.config/.metricsUUID\n",
            "/content/.config/configurations/config_default\n",
            "/content/.config/logs/2019.08.22/16.14.16.878847.log\n",
            "/content/.config/logs/2019.08.22/16.14.02.863676.log\n",
            "/content/.config/logs/2019.08.22/16.14.17.917007.log\n",
            "/content/.config/logs/2019.08.22/16.13.58.179258.log\n",
            "/content/.config/logs/2019.08.22/16.14.13.419782.log\n",
            "/content/sample_data/README.md\n",
            "/content/sample_data/anscombe.json\n",
            "/content/sample_data/mnist_test.csv\n",
            "/content/sample_data/california_housing_train.csv\n",
            "/content/sample_data/california_housing_test.csv\n",
            "/content/sample_data/mnist_train_small.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "TgQ7Brhzl2O6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Jun  7 13:59:26 2019\n",
        "\n",
        "@author: vizentec\n",
        "\n",
        "Image dataset rename and folder segmentation for keras model training\n",
        "\"\"\"\n",
        "def img_prep(srcfolder = 'data', destfolder = 'modeldata'):\n",
        "# Function that copies and renames the images acording to it's class, adding an incremental ID to the name\n",
        "# Such folders are placed inside a folder called \"modeldata\" by default\n",
        "# The inputs are: \n",
        "# * srcfolder = name of the main folder containing the source data (default name: \"data\")\n",
        "# * destfolder = name of the folder where the images will be placed (default name: \"modeldata\")\n",
        "# * backupimg = not yet implemented!!! Variable responsable for indicating if the original dataset must be kept on\n",
        "#               the original folder, default value keeps the backup, to delete set equal to 0(zero)\n",
        "    \n",
        "    # Create the folder tree\n",
        "    import shutil\n",
        "    \n",
        "    try:\n",
        "        shutil.copytree(srcfolder, destfolder)\n",
        "        print(\"Directory '\" + destfolder + \"' created!\")\n",
        "    except FileExistsError:\n",
        "        print(\"Directory '\" + destfolder + \"' already exists!\")\n",
        "        print(\"Delete the '\" + destfolder + \"' folder or choose another name!\")\n",
        "        return\n",
        "    \n",
        "    print(\"Images backed up to '\" + destfolder + \"'!\")\n",
        "    \n",
        "    # Copy and rename the files to the tree\n",
        "    import os\n",
        "        \n",
        "    for classfolder in os.listdir(destfolder):\n",
        "        i = 0\n",
        "        for filename in os.listdir(\"{}/{}\".format(destfolder, classfolder)): \n",
        "            name = classfolder + \"_\" + str(i) + \".jpg\"\n",
        "            src = \"{}/{}\".format(destfolder, classfolder) +'/'+ filename\n",
        "            dst = \"{}/{}\".format(destfolder, classfolder) +'/'+ name\n",
        "            # rename the file \n",
        "            os.rename(src, dst)\n",
        "            i += 1\n",
        "    \n",
        "    # Prints the name of each class and the total amount of images in it\n",
        "    for classfolder in os.listdir(destfolder):\n",
        "        imgquant = os.listdir(\"{}/{}\".format(destfolder, classfolder))\n",
        "        print(\"On class '{}' there are '{}' images\".format(classfolder,len(imgquant)))\n",
        "\n",
        "#%%\n",
        "def img_to_folders(train_size, valid_size, test_size, srcfolder = 'modeldata'):\n",
        "# Function that splits the imagens on folder 'srcfolder' into the folders test, valid and train\n",
        "# * train_size = number of images to be placed on the train folder\n",
        "# * valid_size = number of images to be placed on the valid folder\n",
        "# * test_size = number of images to be placed on the test folder\n",
        "# * srcfolder = name of the main folder containing the source data (default name: \"modeldata\")\n",
        "    import random\n",
        "    import os\n",
        "    from random import seed\n",
        "    from random import sample\n",
        "        \n",
        "    sample_size = train_size + valid_size + test_size\n",
        "    \n",
        "    # seed random number generator\n",
        "    seed(random.randint(1, 1000))\n",
        "    \n",
        "    for imgclass in os.listdir(srcfolder):\n",
        "        images_local = os.listdir(srcfolder+'/'+imgclass)\n",
        "        # select a subset of images without replacement\n",
        "        subset = sample(images_local, sample_size)\n",
        "        \n",
        "        try:\n",
        "            os.makedirs(srcfolder+'/train/'+imgclass)    \n",
        "            os.makedirs(srcfolder+'/valid/'+imgclass)   \n",
        "            os.makedirs(srcfolder+'/test/'+imgclass)\n",
        "            print(\"Folders train, validation and test were created for \" + imgclass)    \n",
        "        except FileExistsError:\n",
        "            print(\"One or more of the folders already exists!\") \n",
        "            \n",
        "        for imgname in subset[:train_size]:    \n",
        "            os.rename('{}/{}/{}'.format(srcfolder, imgclass, imgname), '{}/train/{}/{}'.format(srcfolder, imgclass, imgname))\n",
        "        print('train folder created and ready!')\n",
        "        for imgname in subset[train_size : train_size + valid_size]:\n",
        "            os.rename('{}/{}/{}'.format(srcfolder, imgclass, imgname), '{}/valid/{}/{}'.format(srcfolder, imgclass, imgname))\n",
        "        print('valid folder created and ready!')\n",
        "        for imgname in subset[train_size + valid_size : train_size + valid_size + test_size]:\n",
        "            os.rename('{}/{}/{}'.format(srcfolder, imgclass, imgname), '{}/test/{}/{}'.format(srcfolder, imgclass, imgname))\n",
        "        print('test folder created and ready!')\n",
        "\n",
        "#%%\n",
        "def crop(image_path, coords, save_location):\n",
        "    \"\"\"\n",
        "    @param image_path: The path to the image to edit\n",
        "    @param coords: A tuple of x/y coordinates (x1, y1, width, height)\n",
        "    @param save_location: Path to save the cropped image\n",
        "    \"\"\"\n",
        "    from PIL import Image\n",
        "\n",
        "    image_obj = Image.open(image_path)\n",
        "    cropped_image = image_obj.crop(coords)\n",
        "    cropped_image.save(save_location)\n",
        "\n",
        "#%%\n",
        "import time\n",
        "start = time.time()\n",
        "img_prep('/kaggle/input/tech-problems-images/techproblemsdata', 'modeldata')\n",
        "img_to_folders(5000, 500, 400)\n",
        "print(\"Task done, elapsed time:\" + str(time.time() - start))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZSRAZFGkl2O9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "base_dir = 'modeldata/'\n",
        "train_dir = base_dir + 'train'\n",
        "validation_dir = base_dir + 'valid'\n",
        "test_dir = base_dir + 'test'\n",
        "\n",
        "size_img = 250\n",
        "size_conv = 3\n",
        "size_batch = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NB_nJcqnl2O_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(size_img, size_img), \n",
        "                                                    batch_size=size_batch, class_mode='categorical')\n",
        "validation_generator = validation_datagen.flow_from_directory(validation_dir, target_size=(size_img, size_img), \n",
        "                                                              batch_size=size_batch, class_mode='categorical')\n",
        "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(size_img, size_img), \n",
        "                                                  batch_size=size_batch, class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XUxziXRcl2PB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import VGG19\n",
        "\n",
        "conv_base = VGG19(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(size_img, size_img, 3))\n",
        "\n",
        "conv_base.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AY3jTWxTl2PD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(2048, activation='relu'))\n",
        "model.add(layers.Dense(2048, activation='relu'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "from keras import optimizers\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=1e-5), metrics=['acc'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7DJhb6jhl2PF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "history = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=200,\n",
        "        epochs=50,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mLh2YA-yl2PH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uA0vznytl2PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
        "print('test_acc:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Bw3hDE-ml2PL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('tech_problems_noprep_82p.h5')\n",
        "model_json = model.to_json()\n",
        "with open(\"tech_problems_noprep_82p.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}